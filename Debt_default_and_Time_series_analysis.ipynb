{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmOIrru0GSlMiN3fwvoYhL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranavShashidhara/Country-Default-Prediction/blob/main/Debt_default_and_Time_series_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "data_df = pd.read_csv('World_Bank_Cleared.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8moSoa3rgmFw",
        "outputId": "fcb77a0e-b5c7-4e2c-cb56-1bd360267ae0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTOUvVgUgkfd",
        "outputId": "e5dbcdd7-a873-4d45-b007-23be4d357c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 16827\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004413 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5721\n",
            "[LightGBM] [Info] Number of data points in the train set: 18538, number of used features: 24\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 16827\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032773 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5721\n",
            "[LightGBM] [Info] Number of data points in the train set: 18538, number of used features: 24\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.95      0.97     16827\n",
            "         1.0       0.66      0.99      0.79      1711\n",
            "\n",
            "    accuracy                           0.95     18538\n",
            "   macro avg       0.83      0.97      0.88     18538\n",
            "weighted avg       0.97      0.95      0.96     18538\n",
            "\n",
            "[[15965   862]\n",
            " [   15  1696]]\n"
          ]
        }
      ],
      "source": [
        "# Prepare data\n",
        "X = data_df.drop('DEFAULT', axis=1)\n",
        "y = data_df['DEFAULT']\n",
        "\n",
        "# Apply ADASYN to balance class distribution\n",
        "adasyn = ADASYN(sampling_strategy=0.1, random_state=42)\n",
        "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
        "\n",
        "# Convert 'Year' column to numeric before fitting the model\n",
        "X_resampled['Year'] = pd.to_numeric(X_resampled['Year'], errors='coerce')\n",
        "X = X.dropna()  # Remove any rows with missing values before splitting\n",
        "\n",
        "# Replace special characters and spaces in column names\n",
        "X_resampled.columns = X_resampled.columns.str.replace('[^a-zA-Z0-9_]', '', regex=True)\n",
        "\n",
        "# Initialize LightGBM model for recall (Model 0)\n",
        "model_recall = lgb.LGBMClassifier(\n",
        "    boosting_type='gbdt',\n",
        "    objective='binary',\n",
        "    metric='recall',\n",
        "    class_weight='balanced',\n",
        "    num_leaves=30,\n",
        "    learning_rate=0.01,\n",
        "    min_split_gain=0.01,\n",
        "    min_child_samples=30,\n",
        "    n_estimators=50,\n",
        "    lambda_l2=1,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Initialize LightGBM model for precision (Model 1)\n",
        "model_precision = lgb.LGBMClassifier(\n",
        "    boosting_type='gbdt',\n",
        "    objective='binary',\n",
        "    metric='precision',\n",
        "    class_weight='balanced',\n",
        "    num_leaves=30,\n",
        "    learning_rate=0.01,\n",
        "    min_split_gain=0.01,\n",
        "    min_child_samples=30,\n",
        "    n_estimators=50,\n",
        "    lambda_l2=1,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Define custom scoring functions for precision and recall\n",
        "def custom_recall(y_true, y_pred):\n",
        "    return recall_score(y_true, y_pred)\n",
        "\n",
        "def custom_precision(y_true, y_pred):\n",
        "    return precision_score(y_true, y_pred)\n",
        "\n",
        "# Stratified K-Folds cross-validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store the predictions from both models for combining them later\n",
        "recall_preds = []\n",
        "precision_preds = []\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('recall', model_recall), ('precision', model_precision)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Train the voting classifier on the resampled data\n",
        "voting_clf.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions using the voting classifier\n",
        "y_pred_voting = voting_clf.predict(X_resampled)\n",
        "\n",
        "# Evaluate the performance of the voting classifier\n",
        "print(classification_report(y_resampled, y_pred_voting))\n",
        "print(confusion_matrix(y_resampled, y_pred_voting))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aO14m7A_g-t7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}